{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e603f5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base64 import b64encode\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import pafy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21db31fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDetection:\n",
    "    def __init__(self, path, confidence, video):\n",
    "        \n",
    "        self.model = self.load_model()\n",
    "        self.classes = self.model.names\n",
    "        self.video = video\n",
    "        self.path = path\n",
    "        self.confidence = confidence\n",
    "        self.pixels = {}\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "\n",
    "    def load_model(self):\n",
    "\n",
    "        model = torch.hub.load('ultralytics/yolov5', 'yolov5x',\n",
    "                       pretrained=True, verbose=False)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def generate_pixels_colors(self):\n",
    "        n_red = random.randint(0,255)\n",
    "        n_green = random.randint(0,255)\n",
    "        n_blue = random.randint(0,255)\n",
    "        \n",
    "        return (n_red, n_green, n_blue)\n",
    "    \n",
    "    \n",
    "           \n",
    "    def detect_object_on_frame(self, img):\n",
    "        '''Detect car on a frame and draw the rectangles and lines.'''\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        results = self.model([img[:, :, ::-1]])  # Pass the frame through the model and get the boxes\n",
    "\n",
    "        xyxy = results.xyxy[0].cpu().numpy() # img1 predictions (pandas) to numpy\n",
    "        #      xmin    ymin    xmax   ymax  confidence  class    name\n",
    "        # 0  749.50   43.50  1148.0  704.5    0.874023      0     xx\n",
    "        # 1  433.50  433.50   517.5  714.5    0.687988     27     xx\n",
    "        # 2  114.75  195.75  1095.0  708.0    0.624512      0     xx\n",
    "        # 3  986.00  304.00  1028.0  420.0    0.286865     27     xx\n",
    "\n",
    "        xyxy = xyxy[xyxy[:, 4] >= self.confidence]  # Filter desired confidence\n",
    "        xyxy = xyxy[:, :6]\n",
    "                \n",
    "        for i, (x1, y1, x2, y2, conf, class_) in enumerate(xyxy):\n",
    "            # Draw the boxes\n",
    "            class_detected = self.classes[int(class_)]\n",
    "            \n",
    "            for ii in range(len(xyxy)):\n",
    "                 if class_detected not in self.pixels.keys():\n",
    "                    (r, g, b) = self.generate_pixels_colors()\n",
    "                    self.pixels[class_detected] = (r, g, b)\n",
    "            \n",
    "            img = cv2.rectangle(img, (x1, y1), (x2, y2), (self.pixels[class_detected][:]), 1)\n",
    "            cv2.putText(img, class_detected, (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.65, \n",
    "                        (self.pixels[class_detected]), 2)\n",
    "            \n",
    "            \n",
    "        return img\n",
    "\n",
    "\n",
    "    def __call__(self):\n",
    "        '''Detect people on a video and draw the rectangles and lines.'''\n",
    "        if self.video == True:\n",
    "            # Capture video\n",
    "            \n",
    "            cap = cv2.VideoCapture(self.path)\n",
    "             \n",
    "            # Get video properties\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "            # Define the codec and create VideoWriter object\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "            if os.path.exists('output.avi'):\n",
    "                os.remove('output.avi')\n",
    "            out = cv2.VideoWriter('output.avi', fourcc, fps, (width, height))\n",
    "\n",
    "            # Iterate through frames and detect people\n",
    "            vidlen = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            with tqdm(total=vidlen) as pbar:\n",
    "                while cap.isOpened():\n",
    "                    # Read a frame\n",
    "                    ret, frame = cap.read()\n",
    "                    # If it's ok\n",
    "                    if ret == True:\n",
    "                        frame = self.detect_object_on_frame(frame)\n",
    "                        # Write new video\n",
    "                        out.write(frame)\n",
    "                        pbar.update(1)\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "            # Release everything if job is finished\n",
    "            cap.release()\n",
    "            out.release()\n",
    "            cv2.destroyAllWindows()\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            img = cv2.imread(self.path)\n",
    "     \n",
    "            cv2.imshow('image', self.detect_object_on_frame(img))\n",
    "            cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34458ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model Summary: 476 layers, 87730285 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "YOLOv5  2021-6-23 torch 1.9.0 CUDA:0 (NVIDIA GeForce GTX 1060 6GB, 6144.0MB)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702661057a43491492028d74356edf15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59717 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "<ipython-input-2-21b7b3dd813f>:55: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  img = cv2.rectangle(img, (x1, y1), (x2, y2), (self.pixels[class_detected][:]), 1)\n",
      "<ipython-input-2-21b7b3dd813f>:56: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  cv2.putText(img, class_detected, (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.65,\n"
     ]
    }
   ],
   "source": [
    "a = ObjectDetection(r\"C:\\Users\\bruno\\Desktop\\avenue.mp4\", 0.5, video=True)\n",
    "a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba4525b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b34ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09df0278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
